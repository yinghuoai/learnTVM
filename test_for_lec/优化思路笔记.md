# 首先需要理清楚现在已经掌握的。

## 论文：关于深度学习编译器中的计算图优化
    
    优化这个词呢，是比较泛和笼统的。
    而如果是具体的某种demo类的优化方式的话呢，也是不足以成为一篇小论文的。
    所以在优化和demo中间，可以叫做一种计算图替换的优化方式。

    这里的计算图替换概念：优化的核心就是子图的等价变换
    在计算图中尝试匹配特定的子图结构，找到目标子图结构之后，
    通过等价替换的方式，将其替换为对硬件更加友好的子图结构。

    插一句，这里的“对硬件更加友好”其实就是在新的硬件上也是利用局部有效性。
    时间和空间，减少频繁的访问内存，尽量能够更加高效的利用到缓存结构。

    计算密集型算子：卷积，全连接等
    访存密集型算子：大部分是Element-wise 算子，比如Relu，Element—wise sum等

    在典型的深度学习模型中，一般计算密集型和访存密集型是相伴出现的，
    最简单的例子就是“Conv+Relu", Relu算子可以直接取Conv算子的计算结果进行计算
    因此，可以尝试将二者融合为一个算子来进行计算，
    从而减少内存访问延时和带宽压力，提高执行效率

例如：**Conv + Conv + Sum + ReLU**的融合，从图中我们可以看到融合后的算子减少了两个内存的读和写的操作，优化了Conv的输出和Sum的输出的读和写的操作。



![Elementwise算子融合](https://img-blog.csdnimg.cn/952190c4aad04cc8ae280ccdb30bf222.png)


现在掌握的demo情况：
    1. 运算数学规律化简relay的算子组成的表达式这样的计算图
        情况：有收益，但是提升不是很明显
        原因分析：运用的数学化简单一，并且是手动，化简的原表达式模型太小。
    2. 计算图特征匹配和替换
        情况：匹配到相应的relay计算图，然后进行替换，同样是手动，一对一匹配。
    3. 还没有尝试，但是有相应的想法
        情况：
            1. 比如将一个大的卷积分解为多个小的卷积进行计算，然后最后进行重组。
            2. 将多个初始的relay算子“分解”为多个基础算子，比如加减乘之类的，然后统一进行重组为新的更加高效率的算子
        面临的问题：
            1. 如何分解？
            2. 如何重组？
            3. 如何确保结果是优化的？

上面的关于还没有尝试，但是有相应想法的情况脱胎于自己的思考和华为的mindspore。

除了上述针对特定算子类型结构的融合优化外，基于自动算子生成技术，还可以实现更灵活、更极致的通用优化。以 MindSpore 的图算融合技术为例，图算融合通过“算子拆解、算子聚合、算子重建”三个主要阶段（如图）让计算图中的计算更密集，并进一步减少低效的内存访问。



![图算融合](https://img-blog.csdnimg.cn/881de7e043dc4c9289199cad5449424f.png)



算子拆解阶段（Expander）将计算图中一些复杂算子（composite op，图中Op1、Op3、Op4）展开为计算等价的基本算子组合（ 图中虚线正方形框包围着的部分）；在算子聚合阶段（Aggregation），将计算图中将基本算子（basic op，如图中Op2）、拆解后的算子（expanded op）组合融合，形成一个更大范围的算子组合；在算子重建阶段（Reconstruction）中，按照输入tensor到输出tensor的仿射关系将基本算子进行分类：elemwise、 broadcast、reduce、transform等，并在这基础上归纳出不同的通用计算规则（如 elemwise + reduce 规则：elemwise + reduce在满足一定条件后可以高效执行），根据这些计算规则不断地从这个大的算子组合上进行分析、筛选，最终重新构建成新的算子（如图中虚线正方形包围的两个算子 New Op1 和 New Op2）。图算融合通过对计算图结构的拆解和聚合，可以实现跨算子边界的联合优化；并在算子重建中，通过通用的计算规则，以必要的访存作为代价，生成对硬件更友好、执行更高效的新算子。









除了这些之外，还有上陈天奇的课的体会以及相应的练习代码等

# 陈天奇课程体会

目前为止，总共三课，明天应该会更新第四课。










